# data/toolRatings.yml

Agentic Coding:
  "Claude Code":
    rating: 9
    notes: "Great value with Claude Max 5 subscription, fast, flexible, strong coding abilities, high quality outcomes. Cons: Config files are a mess <b>\n\n*Highly recommend!*</b>"
    link: "https://claude.ai/code"
  "Cline":
    rating: 8
    notes: "Best VSCode extension based agent, high quality outcomes. Cons: Consumption based pricing, although you can leveraging Claude Code's subscription it's a bit slower <b>\n\n*Highly recommend!*</b>"
  "Gemini CLI":
    rating: 4
    notes: "Not as good as Claude Code or Cline."
  "Crush":
    rating: 4
    notes: "Great UI, works with any capable model. Cons: Lacks some features and you have to pay for consumption."
  "Github Copilot Agent":
    rating: 3
    notes: "Easy to use, good VSCode integration, huge community. Cons: Slow, heavily rate and token limited, needs a lot of hand holding. Expensive compared to what you get from Claude Code w/ Max 5"
    link: "https://github.com/features/copilot"
  "Amazon Kiro":
    rating: 3
    notes: "Requires you to run a VSCode fork, lacks a lot of features and configuration other tools have had for a long time, can be buggy, tends to build over-engineered solutions, slow, needs a lot of hand holding. Expensive compared to what you get from Claude Code w/ Max 5"

Non-Agentic Copilots:
  "Github Copilot":
    rating: 8
    notes: "Easy to use, good VSCode integration, huge community. Cons: Sometimes stops responding, limited to single file editing, sometimes only returns a single line at a time. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/features/copilot"
  "Continue.dev":
    rating: 6
    notes: "Traditional copilot style completions, decent UI, good performance, big community."
    link: "https://continue.dev/"
  "Amazon Q":
    rating: 2
    notes: "Poor quality suggestions, buggy integration experience, limited to single file editing, not as good as Github Copilot or Continue.dev with local LLMs."

Clients:
  "Msty":
    rating: 7
    notes: "Lots of potential, nice UI, has branching conversations and document libraries for RAG. Cons: Electron, limited configuration."
    link: "https://msty.app"
  "Open WebUI":
    rating: 7
    notes: "Rapidly being developed, Fast UI, RAG, Configurable, Diagram generation. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/open-webui/open-webui"
  "LM-Studio":
    rating: 7
    notes: "Great UI, Performs well. Cons: Electron, Closed Source, Falls behind on llama.cpp updates."
    link: "https://lmstudio.ai/"
  "Jan":
    rating: 3
    notes: "UI feels disjointed, Electron, Limited integration when running existing LLM servers."
    link: "https://github.com/janhq/jan/"
  "Anything LLM":
    rating: 4
    notes: "Excellent RAG performance, support for browsing, search, confluence, youtube tooling. Cons: Very ugly UI, Electron"
    link: "https://github.com/Mintplex-Labs/anything-llm/"
  "Lobe Chat":
    rating: 2
    notes: "Attractive UI, Plugin ecosystem, Good for building agent personas. Cons: Plugin ecosystem seems to be broken now, Limited and confusing configurability."
    link: "https://github.com/lobehub/lobe-chat/"
  "BigAGI":
    rating: 4
    notes: "Has unique 'Beam' feature for generating responses from multiple models, Fast UI, Diagram generation. Cons: Not very configurable. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/enricoros/big-AGI/"
  "Bolt":
    rating: 6
    notes: "Great native macOS client for LLMs, Responsive developer, Currently go-to for a desktop app. Cons: Lacks RAG, Expensive. <b>\n\n*Highly recommend!*</b>"
    link: "https://boltai.com/"
  "GPT4All":
    rating: 4
    notes: "Open Source. Cons: Electron, Limited configurability, Ugly UI."
    link: "https://www.nomic.ai"

Servers:
  "Llama.cpp with LlamaSwap":
    rating: 9
    notes: "Simply an amazing feat of engineering, rapid development, huge community, lots of configuration options. Running it with llama-swap makes it easy to hot load/unload models and configuration sets."
    link: "https://github.com/ggerganov/llama.cpp/"
  "Ollama":
    rating: 7
    notes: "As easy to use as Docker, Makes running models very easy, large community. Cons: Lack of configuration and features can sometimes lag behind llama.cpp, slow to contribute to."
    link: "https://github.com/ollama/ollama/"
  "vLLM":
    rating: 4
    notes: "Fast, good model support. Cons: Can be a pain to setup and configure, no model hot loading, limited quantisation options."
    link: "https://github.com/vllm-project/vllm/"
  "ExLlamav2":
    rating: 4
    notes: "Fast, efficient LLM model serving, excellent caching. Cons: Not as well maintained as llama.cpp <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/turboderp/exllamav2"
  "Tensorrt-LLM":
    rating: 2
    notes: "Fast. Cons: Horribly terrible to setup, confusing documentation, complex model configuration."
    link: "https://github.com/NVIDIA/TensorRT-LLM/"
  "Mistralrs":
    rating: 4
    notes: "Unique features such as combining unrelated models as a MoE, rapid development, friendly developer. Cons: Confusing runtime arguments, limited model support, is a pain to configure and remember parameters for."
    link: "https://github.com/EricLBuehler/mistral.rs"

Imagegen:
  "Invokeai":
    rating: 9
    notes: "My go-to imagegen tool, lots of configuration, big community, responsive devs, good UI, great performance. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/invoke-ai/InvokeAI"
  "Comfy":
    rating: 5
    notes: "Very powerful, huge community, lots of plugins. Cons: UI is very complicated, a lack of workflow (kind of by design), No model management built in."
    link: "https://github.com/comfyanonymous/ComfyUI"
  "Automatic1111":
    rating: 4
    notes: "Powerful, huge community, lots of plugins. Cons: Terrible UI, configuration and model management is painful, UI has lack of flow."
    link: "https://github.com/AUTOMATIC1111/stable-diffusion-webui"
  "Draw Things":
    rating: 4
    notes: "Well built app, unique and interesting UI. Cons: Can be slow."
    link: "https://drawthings.ai/"
  "Facefusion":
    rating: 8
    notes: "Excellent for creating memes with coworkers, fast, easy to use. Cons: The Gradio interface has some limitations.  <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/facefusion/facefusion/"
  "Topaz Photo AI":
    rating: 7
    notes: "Powerful, high quality upscaling. Cons: Expensive, closed source."
    link: "https://www.topazlabs.com/topaz-photo-ai"
  "Topaz Video AI":
    rating: 9
    notes: "Best in class for video upscaling and quality enhancement. Cons: Expensive, closed source. <b>\n\n*Highly recommend!*</b>"
    link: "https://www.topazlabs.com/topaz-video-ai"

Utils:
  "nvapi":
    rating: 8
    notes: "My tool for exposing NVidia GPU metrics as an API, I find it very useful, but then... I would say that! <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/sammcj/nvapi/"
  "gollama":
    rating: 8
    notes: "My fast TUI for managing Ollama models, plugs the gap in Ollama's functionality. Cons: I'm always creating and finding bugs. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/sammcj/gollama/"
  "Langfuse":
    rating: 5
    notes: "Strong Observability platform for LLMs."
    link: "https://github.com/langfuse/langfuse/"
  "PR-Agent":
    rating: 7
    notes: "Powerful too for AI in CI/CD pipelines (or locally), can review PRs, security, complexity etc...<b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/Codium-ai/pr-agent"
  "Ingest":
    rating: 8
    notes: "My tool for ingesting directories of code/data for passing to LLMs. Has advanced vRAM and token estimations <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/sammcj/ingest"

SaaS Providers:
  "Claude":
    rating: 9
    notes: "Since Claude Sonnet 3.5 has been quite good at coding, especially with 'projects' and generating code as text attachments. Cons: Expensive, get rate limited all the time <b>\n\n*Highly recommend!*</b>"
    link: "https://claude.ai"
  "OpenAI":
    rating: 7
    notes: "The O.G. of modern AI SaaS providers. Cons: Hostile to Open Source, Too much VC funding, Lobbies Governments, For-profit, Expensive."
    link: "https://openai.com/"
  "Gemini":
    rating: 7
    notes: "The Pro and image editing models can be useful, but they need a lot of hand holding and are very happy clappy."
  "Qwen (API)":
    rating: 6
    notes: "Open weight coding models, fast. Cons: Historical and political inaccuracies, probably fine for coding."
    link: "https://deepseek.ai/"
  "DeepSeek (API)":
    rating: 6
    notes: "Open weight coding models, fast. Cons: Historical and political inaccuracies, probably fine for coding."
    link: "https://deepseek.ai/"
  "TogetherAI":
    rating: 5
    notes: "Lots of Open Source models available, Very fast, drop in replacement for OpenAI Cons: Can be expensive for larger models. <b>\n\n*Highly recommend!*</b>"
    link: "https://www.together.ai"
  "OpenRouter":
    rating: 6
    notes: "Lots of models to choose from, easy to drop in to replace OpenAI. Cons: Can be a bit laggy at times."
    link: "https://openrouter.ai"
  "Groq":
    rating: 4
    notes: "Incredibly fast, uses Open Source models, Free. Cons: Old, limited models."
    link: "https://groq.com/"


Data and Training:
  "Kohya_SS":
    rating: 9
    notes: "Very powerful ImageGen training and fine tuning, lots of configuration options, flexible, decent community, fast. Cons: Some documentation not in English, Gradio based UI has it's limits. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/bmaltais/kohya_ss"
  "Llama Factory":
    rating: 6
    notes: "Interface for various fine-tuning/training LLM tools such as unsloth. Cons: Gradio UI has its limits, not always clear why something goes wrong. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/hiyouga/LLaMA-Factory"
