# data/toolRatings.yml
Codegen:
  "Continue.dev":
    rating: 7
    notes: "Decent UI, good performance, big community. Cons: Models have to be manually configured. <b>\n\n*Highly recommend!*</b>"
    link: "https://continue.dev/"
  "Github Copilot":
    rating: 8
    notes: "Easy to use, good VSCode integration, huge community. Cons: Sometimes stops responding, sometimes only returns a single line at a time. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/features/copilot"
  "Code2Prompt":
    rating: 9
    notes: "Very useful tool for ingesting directories of code/data for passing to LLMs. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/mufeedvh/code2prompt"
  "Llama Autocoder":
    rating: 4
    notes: "Very easy to use, Very fast, Good for when you just want AI to write code for you. Cons: Limited configurability."
    link: "https://github.com/10Nates/ollama-autocoder"
  "Aider":
    rating: 6
    notes: "Very powerful, supports updating existing code, good for codegen. Cons: The UI feels a bit slow (high latency) and clunky."
    link: "https://aider.chat"

Clients:
  "MindMac":
    rating: 6
    notes: "Good native macOS client for LLMs, has a decent set of features. Cons: Can be a bit slow at times, UI feels dated."
    link: "https://mindmac.app/"
  "Msty":
    rating: 6
    notes: "Lots of potential, nice UI, has branching conversations and document libraries for RAG. Cons: Electron, limited configuration."
    link: "https://msty.app"
  "Librechat":
    rating: 3
    notes: "Attractive UI. Cons: Configuration is complex / brittle."
    link: "https://www.librechat.ai"
  "Open WebUI":
    rating: 7
    notes: "Rapidly being developed, Fast UI, RAG, Configurable, Diagram generation. Cons: Commonly used configuration is buried away in 'advanced' settings. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/open-webui/open-webui"
  "LM-Studio":
    rating: 6
    notes: "Great UI, Performs well. Cons: Electron, Closed Source, Falls behind on llama.cpp updates."
    link: "https://lmstudio.ai/"
  "Jan":
    rating: 6
    notes: "Nice UI, some good futures. Cons: Electron, Limited integration with Ollama."
    link: "https://github.com/janhq/jan/"
  "Anything LLM":
    rating: 5
    notes: "Excellent RAG performance, support for browsing, search, confluence, youtube tooling. Cons: Very ugly UI, Electron"
    link: "https://github.com/Mintplex-Labs/anything-llm/"
  "Lobe Chat":
    rating: 3
    notes: "Very attractive UI, Plugin ecosystem, Good for building agent personas. Cons: Plugin ecosystem seems to be broken now, Limited and confusing configurability."
    link: "https://github.com/lobehub/lobe-chat/"
  "BigAGI":
    rating: 7
    notes: "Has unique 'Beam' feature for generating responses from multiple models, Fast UI, Diagram generation. Cons: Not very configurable. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/enricoros/big-AGI/"
  "Bolt":
    rating: 8
    notes: "Great native macOS client for LLMs, Responsive developer, Currently go-to for a desktop app. Cons: Lacks RAG, Expensive. <b>\n\n*Highly recommend!*</b>"
    link: "https://boltai.com/"
  "Khoj":
    rating: 2
    notes: "RAG. Cons: Lacks configurability, Dated UI."
    link: "https://khoj.dev/"
  "Mods":
    rating: 3
    notes: "Very pretty TUI, fast and lightweight. Cons: Limited configurability, no RAG."
    link: "https://github.com/charmbracelet/mods"
  "GPT4All":
    rating: 4
    notes: "Open Source, decent for RAG, . Cons: Electron, Limited configurability, Ugly UI."
    link: "https://www.nomic.ai"
  "Kerlig":
    rating: 6
    notes: "Fast, lightweight (despite being Electron) and well integrated with macOS, visually pleasing UI. Cons: Closed source, could do with some more configuration options."
    link: "https://kerlig.com/"

Servers:
  "Ollama":
    rating: 9
    notes: "As easy to use as Docker, Makes running models very easy, uses Llama.cpp, Huge community. Cons: Features can sometimes lag behind llama.cpp, no support for other servers such as Exllamav2 or MLX. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/ollama/ollama/"
  "ExLlamav2":
    rating: 9
    notes: "Incredibly fast, efficient LLM model serving, excellent caching. Cons: limited servers available (I recommend TabbyAPI). <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/turboderp/exllamav2"
  "Llama.cpp":
    rating: 10
    notes: "Simply an amazing feat of engineering, rapid development, huge community, lots of configuration options. Cons: No concept of model management, server is limited without a wrapper like Ollama."
    link: "https://github.com/ggerganov/llama.cpp/"
  "llama.cpp RPC":
    rating: 5
    notes: "Great concept of distributed inference. Cons: Crashes often, limited server configuration."
    link: "https://github.com/ggerganov/llama.cpp/"
  "TabbyAPI":
    rating: 7
    notes: "Really easy way to host Exllamav2 models. Cons: Doesn't properly free VRAM after unload."
    link: "https://github.com/theroyallab/tabbyAPI/"
  "Tensorrt-LLM":
    rating: 2
    notes: "Fast. Cons: Horribly terrible to setup, confusing documentation, complex model configuration."
    link: "https://github.com/NVIDIA/TensorRT-LLM/"
  "vLLM":
    rating: 4
    notes: "Fast. Cons: Can be a pain to setup and configure."
    link: "https://github.com/vllm-project/vllm/"
  "Localai":
    rating: 1
    notes: "Offers lots of features. Cons: A pain to configure and setup, model management is over-complicated."
    link: "https://localai.io"
  "Mistralrs":
    rating: -0
    notes: "Want to checkout (again): When exllamav2 support is merged - keeping an eye on https://github.com/EricLBuehler/mistral.rs/issues/546. Fast, Rapid development. Cons: Currently only supports GGUF, can be a pain to configure."
    link: "https://github.com/EricLBuehler/mistral.rs"
  "Aphrodite engine":
    rating: 4
    notes: "Very fast. Cons: Does not support running with an odd-number of GPUs, A bit of a pain to configure."
    link: "https://github.com/PygmalionAI/aphrodite-engine"

Pipelines / Integrations:
  "Flowise":
    rating: 6
    notes: "Good UI, Lots of plugins, inbuilt API for no-code creations. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/FlowiseAI/Flowise/"
  "Verba":
    rating: 3
    notes: "Good at RAG. Cons: Limited features and configurability."
    link: "https://github.com/weaviate/Verba"
  "Fabric":
    rating: 4
    notes: "Good for quickly piping YouTube videos into LLMs. Cons: Can be a tad slow, difficult to manage prompt library/templates."
    link: "https://github.com/danielmiessler/fabric/"
  "Crewai":
    rating: 6
    notes: "Incredibly powerful, easy to do the basics. Cons: Could do with a UI. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/joaomdmoura/crewAI/"
  "Autogen":
    rating: 4
    notes: "Felt over-complicated and a bit dated compared to CrewAI."
    link: "https://github.com/microsoft/autogen/"
  "Danswer":
    rating: 7
    notes: "Strong integrations with Slack, Confluence etc..."
    link: "https://github.com/danswer-ai/danswer/"
  "HomeAssistant AI Integration":
    rating: 6
    notes: "Awesome to be able to integration Home Assistant with Local LLMs. Limited configuration and somewhat jacky onboarding - probably a limitation of Home Assistant."
    link: "https://github.com/jekalmin/extended_openai_conversation"
  "Perplexica":
    rating: 5
    notes: "Nice self-hostable Perplexity clone."
    link: "https://github.com/ItzCrazyKns/Perplexica/"
  "Langflow":
    rating: 4
    notes: "Cons: Just doesn't seem as a good as Flowise."
    link: "https://www.langflow.org/"
  "Jupyter Notebook":
    rating: 4
    notes: "Alright for quick prototyping and testing code in isolation, suffers from the usual python packaging ecosystem and a bit of a clunky UI with no copilot."
    link: "https://jupyter.org/"

Imagegen:
  "Automatic1111":
    rating: 4
    notes: "Powerful, huge community, lots of plugins. Cons: Terrible UI, configuration and model management is painful, UI has lack of flow."
    link: "https://github.com/AUTOMATIC1111/stable-diffusion-webui"
  "Draw Things":
    rating: 4
    notes: "Well built app, unique and interesting UI. Cons: Can be slow."
    link: "https://drawthings.ai/"
  "Facefusion":
    rating: 8
    notes: "Excellent for creating memes with coworkers, fast, easy to use. Cons: The Gradio interface has some limitations.  <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/facefusion/facefusion/"
  "Fooocus":
    rating: 1
    notes: "Cons: Everything? Seems pretty limited."
    link: "https://github.com/lllyasviel/Fooocus"
  "Invokeai":
    rating: 9
    notes: "My go-to imagegen tool, lots of configuration, big community, responsive devs, good UI, great performance. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/invoke-ai/InvokeAI"
  "Sogni":
    rating: 3
    notes: "A decent native application for ImageGen, a bit faster than Draw Things. Cons: Limited configuration."
    link: "https://www.sogni.ai"
  "Stability Matrix":
    rating: 7
    notes: "Handy tool for when you quickly want to install ComfyUI/InvokeAI/Automatic1111/StableSwarmUI. Cons: Limited packages available."
    link: "https://github.com/LykosAI/StabilityMatrix"
  "Stable Swarm":
    rating: 5
    notes: "Has potential, in some ways easier to use than Automatic1111. Cons: UI is a bit clunky."
    link: "https://github.com/Stability-AI/StableSwarmUI"
  "Topaz Photo AI":
    rating: 7
    notes: "Powerful, high quality upscaling. Cons: Expensive, closed source."
    link: "https://www.topazlabs.com/topaz-photo-ai"
  "Topaz Video AI":
    rating: 9
    notes: "Best in class for video upscaling and quality enhancement. Cons: Expensive, closed source. <b>\n\n*Highly recommend!*</b>"
    link: "https://www.topazlabs.com/topaz-video-ai"
  "Stable Diffusion XL":
    rating: 9
    notes: "Really powerful once you get the hang of prompting, huge community, lots of LoRAs, Lots of fine tunes. <b>\n\n*Highly recommend!*</b>"
    link: "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
  "Pinokio":
    rating: 4
    notes: "Interesting concept to quickly try new tools out."
    link: "https://pinokio.computer"
  "Comfy":
    rating: 5
    notes: "Very powerful, huge community, lots of plugins. Cons: UI is very complicated, a lack of workflow (kind of by design), No model management built in."
    link: "https://github.com/comfyanonymous/ComfyUI"

Data and Training:
  "Kohya_SS":
    rating: 9
    notes: "Very powerful ImageGen training and fine tuning, lots of configuration options, flexible, decent community, fast. Cons: Some documentation not in English, Gradio based UI has it's limits. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/bmaltais/kohya_ss"
  "Augment Toolkit":
    rating: 6
    notes: "Very interesting one of a kind tool for generating training datasets. Cons: Built for the role play community of which I'm not into, needs a lot of tweaking. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/e-p-armstrong/augmentoolkit"
  "RefactAI":
    rating: 5
    notes: "Excellent UI for fine tuning models and serving LLMs for code completion. Cons: Limited configurability, limited models, fine tuning can be a bit slow compared to unsloth etc..."
    link: "https://refact.ai"
  "Llama Factory":
    rating: 6
    notes: "Interface for various fine-tuning/training LLM tools such as unsloth. Cons: Gradio UI has its limits, not always clear why something goes wrong. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/hiyouga/LLaMA-Factory"
  "H2O Studio":
    rating: 2
    notes: "Quite powerful for training. Cons: Feels very heavy (Java?)"
    link: "https://h2o.ai"
  "Unsloth":
    rating: 7
    notes: "Very powerful, lots of configuration options, fast, good community. Cons: No native UI, but can be used with Llama Factory <b>\n\n*Highly recommend!*</b>"
    link: "https://unsloth.com"

Observability / Utils:
  "nvapi":
    rating: 9
    notes: "My tool for exposing NVidia GPU metrics as an API, I find it very useful, but then... I would say that! <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/sammcj/nvapi/"
  "gollama":
    rating: 9
    notes: "My fast TUI for managing Ollama models, plugs the gap in Ollama's functionality. Cons: I'm always creating and finding bugs. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/sammcj/gollama/"
  "parllama":
    rating: 3
    notes: "A TUI for managing Ollama models, has some neat ideas. Cons: Very slow / laggy, not very user friendly."
    link: "https://github.com/paulrobello/parllama/"

Libraries:
  "llm-scraper":
    rating: -0
    notes: "Want to checkout: Scrapes Websites to data for LLMs for LLM ingestion"
    link: "https://github.com/mishushakov/llm-scraper"
  "Litellm":
    rating: 6
    notes: "Good for managing many LLM providers and models in code."
    link: "https://github.com/BerriAI/litellm/"
  "Langfuse":
    rating: 5
    notes: "Strong Observability platform for LLMs."
    link: "https://github.com/langfuse/langfuse/"

Multimodal:
  "Llavavision":
    rating: 5
    notes: "Neat tool to demo vision models, can use with iPhone to live comment from LLMs on the camera feed. Cons: Limited configurability, no updates in a while."
    link: "https://github.com/aitecnico/llavavision/"
  "Text-generation-webui":
    rating: 7
    notes: "Very powerful, big community, lots of models and inference servers supported, frequent updates. Cons: Very clunky Gradio UI. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/oobabooga/text-generation-webui/"
  "TTS-generation-webui":
    rating: 6
    notes: "Like Text Generation WebUI but for Audio. Cons: Not always clear why you get good/bad results."
    link: "https://github.com/rsxdalv/tts-generation-webui"
  "Whisper":
    rating: 7
    notes: "Powerful STT"
    link: "https://github.com/openai/whisper"
  "Piper":
    rating: 8
    notes: "Powerful TTS"
    link: "https://github.com/rhasspy/piper"
  "OpenWakeWord":
    rating: 6
    notes: "Wake word detection for IoT, easy to train new wake word models. Cons: Can be a bit heavy and slow for low power devices."
    link: "https://github.com/dscripka/openWakeWord"
  "MicroWakeWord":
    rating: 6
    notes: "Fast and light wake words for IoT. Cons: Limited configurability and very hard to train new wake word models. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/kahrendt/microWakeWord"

SaaS Providers:
  "Claude":
    rating: 7
    notes: "Since Claude Sonnet 3.5 has been quite good at coding, especially with 'projects' and generating code as text attachments. Cons: Expensive, get rate limited all the time <b>\n\n*Highly recommend!*</b>"
    link: "https://claude.ai"
  "TogetherAI":
    rating: 8
    notes: "Lots of Open Source models available, Very fast, drop in replacement for OpenAI Cons: Can be expensive for larger models. <b>\n\n*Highly recommend!*</b>"
    link: "https://www.together.ai"
  "OpenRouter":
    rating: 6
    notes: "Lots of models to choose from, easy to drop in to replace OpenAI. Cons: Can be a bit laggy at times."
    link: "https://openrouter.ai"
  "Groq":
    rating: 6
    notes: "Incredibly fast, uses Open Source models, Free. Cons: Closed source hardware, web UI is very basic, limited models."
    link: "https://groq.com/"
  "OpenAI":
    rating: 5
    notes: "The O.G. of modern AI SaaS providers. Cons: Hostile to Open Source, Too much VC funding, Lobbies Governments, For-profit, Expensive."
    link: "https://openai.com/"
  "Github Copilot":
    rating: 8
    notes: "Easy to use, good VSCode integration, huge community. Cons: Sometimes stops responding, sometimes only returns a single line at a time. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/features/copilot"
  "Kagi AI":
    rating: 5
    notes: "Kagi search engine is IMO the best in the business, it has some AI based features such as summarisation and question answering. Lots of potential."
    link: "https://help.kagi.com/kagi/ai/kagi-ai.html"
  "Elevenlabs":
    rating: 6
    notes: "Great webUI, lots of models, easy to use. Cons: Can be expensive when you go over the free tier."
    link: "https://elevenlabs.io/"
  "Suno":
    rating: 5
    notes: "Fun"
    link: "https://suno.com/"
  "01.ai":
    rating: 4
    notes: "They offered me a free trial of Yi-Large which was a good small-context model, Easy drop in replacement for OpenAI. Cons: Very small context window sizes in the Yi Models"
    link: "https://01.ai/"
  "DeepSeek AI":
    rating: 6
    notes: "STOA (July 2024) Open Source coding models, fast. Cons: Web interface is a bit limited, more of a tech demo."
    link: "https://deepseek.ai/"

Methods and Techniques:
  "MoE":
    rating: 8
    notes: "Mixture of Experts can offer greatly improved model performance with less compute overhead. Cons: Still uses the VRAM of all the models combined, can't easily swap out experts. <b>\n\n*Highly recommend!*</b>"
    link: "https://huggingface.co/blog/moe"
  "AnyMoE":
    rating: -0
    notes: "Want to checkout: A more flexible version of MoE, can use any model or any architecture as an expert."
    link: "https://github.com/EricLBuehler/mistral.rs/blob/master/docs/ANYMOE.md"
  "MoA":
    rating: 8
    notes: "I've wanted this from day 1 working with LLMs, simple, effective, easy to use. Cons: Slow, no real UI based apps/clients support this method yet. <b>\n\n*Highly recommend!*</b>"
    link: "https://github.com/togethercomputer/MoA/"
  "RAG":
    rating: 6
    notes: "Useful for data retrieval, Fast. Cons: Not good for codegen, often lacks context."
    link: ""
