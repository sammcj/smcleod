---
title: "LLM FAQ"
description: "Frequently Asked Questions about LLMs and AI"
aliases: ["llm", "faq", "frequently-asked-questions","llm-faq","ollama-faq"]
tags: ["ai", "tools", "llm", "tech", "llms", "ollama","llama","faq","ollama faq","llm faq"]
author: "Sam McLeod"
norss: false
comments: false
showDate: true
subtitle: "Frequently Asked Questions about LLMs and AI"
hidemeta: false
readingTime: true
ShowReadingTime: true
ShowWordCount: false
ShowBreadCrumbs: true
ShowPostNavLinks: true
mermaid: true
disableShare: false
disableHLJS: false
UseHugoToc: false
hideSummary: false
ShowRssButtonInSectionTermList: true
# cover:
#   image: "diagram-gen.png"
#   alt: "DiagramGen"
#   hidden: false
toc:
  enable: true
  auto: true
draft: true
---

<!-- markdownlint-disable MD025 -->

## Ollama

"Is Ollama just a wrapper for Llama.cpp?"

No.
Ollama uses llama.cpp as it's inference engine, but provides a mostly different set of features.
